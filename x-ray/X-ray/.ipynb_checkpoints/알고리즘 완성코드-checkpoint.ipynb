{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f63d21-5e5c-414b-b4a5-3fc23d9cf500",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall protobuf\n",
    "!pip install protobuf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5d4d9-6c28-4c5a-8220-78f4da775e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "main_path = \"C:/Users/myong/Desktop/x-ray/input/archive/chest_xray/chest_xray\"\n",
    "train_path = os.path.join(main_path, \"train\")\n",
    "test_path = os.path.join(main_path, \"test\")\n",
    "val_path = os.path.join(main_path, \"val\")\n",
    "\n",
    "# ë°ì´í„° ì¦ê°• ì„¤ì • (ê°•í™”ëœ ë°ì´í„° ì¦ê°•)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(256, 256), #ì´ë¯¸ì§€ í¬ê¸°\n",
    "    batch_size=64, # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì ˆ\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(256, 256), #ì´ë¯¸ì§€ í¬ê¸°\n",
    "    batch_size=64, # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì ˆ\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(256, 256), #ì´ë¯¸ì§€ í¬ê¸°\n",
    "    batch_size=64, # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì ˆ\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# CNN ëª¨ë¸ êµ¬ì„±\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution Layer 1\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))  # input_shape ìˆ˜ì •\n",
    "model.add(BatchNormalization())  # Batch Normalization ì¶”ê°€\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolution Layer 2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolution Layer 3\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolution Layer 4\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))  # ë“œë¡­ì•„ì›ƒ ìœ ì§€\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# ëª¨ë¸ ì»´íŒŒì¼\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= 'Adam',  # ê¸°ë³¸ í•™ìŠµë¥ \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ì½œë°± ì„¤ì • (EarlyStopping + ReduceLROnPlateau)\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=200,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[es]\n",
    ")\n",
    "\n",
    "# í•™ìŠµ ê²°ê³¼ ì‹œê°í™”\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label=\"Training accuracy\")\n",
    "plt.plot(val_acc, label=\"Validation accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0.5, 1)\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label=\"Training Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=3000)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "\n",
    "# --- Content from /mnt/data/analysis.py ---\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "# í˜ì´ì§€ ì œëª© ì„¤ì •\n",
    "st.set_page_config(\n",
    "    page_title=\"MISA\",\n",
    "    page_icon=\"ğŸ©»\",\n",
    ")\n",
    "\n",
    "def show():\n",
    "    st.title(\"Image Analysis & Comparison\")\n",
    "\n",
    "    # ë‘ ì´ë¯¸ì§€ ì—…ë¡œë“œ\n",
    "    uploaded_image1 = st.file_uploader(\"Upload Image 1\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "    uploaded_image2 = st.file_uploader(\"Upload Image 2\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "    if uploaded_image1 and uploaded_image2:\n",
    "        # ì´ë¯¸ì§€ ì—´ê¸°\n",
    "        image1 = Image.open(uploaded_image1)\n",
    "        image2 = Image.open(uploaded_image2)\n",
    "\n",
    "        # ì´ë¯¸ì§€ í¬ê¸° ë¹„êµ\n",
    "        size1 = image1.size  # (width, height)\n",
    "        size2 = image2.size  # (width, height)\n",
    "\n",
    "        # ì´ë¯¸ì§€ ì¶œë ¥\n",
    "        # 2ê°œì˜ ì—´ ìƒì„±\n",
    "        col1, col2 = st.columns(2)\n",
    "\n",
    "        with col1:\n",
    "            st.image(image1, caption=\"Image 1\", use_column_width=True)\n",
    "\n",
    "        with col2:\n",
    "            st.image(image2, caption=\"Image 2\", use_column_width=True)\n",
    "\n",
    "        # í¬ê¸° ë¹„êµ ê²°ê³¼ ì¶œë ¥\n",
    "        if size1 == size2:\n",
    "            st.success(f\"The images are of the same size: {size1}.\")\n",
    "        else:\n",
    "            st.error(f\"The images have different sizes: Image 1 size: {size1}, Image 2 size: {size2}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show()\n",
    "\n",
    "\n",
    "# --- Content from /mnt/data/results.py ---\n",
    "# í˜ì´ì§€ ì œëª© ì„¤ì •\n",
    "st.set_page_config(\n",
    "    page_title=\"MISA\",\n",
    "    page_icon=\"ğŸ©»\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\")\n",
    "    \n",
    "\n",
    "\n",
    "alt.themes.enable(\"dark\")\n",
    "\n",
    "# ë„ë„› ì°¨íŠ¸ ê·¸ë¦¬ê¸° í•¨ìˆ˜\n",
    "def draw_donut_chart(labels, sizes, colors):\n",
    "    plt.style.use('dark_background')\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))  # ì°¨íŠ¸ í¬ê¸° ì¡°ì •\n",
    "    wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors,\n",
    "                                       autopct='%1.1f%%', startangle=140)\n",
    "\n",
    "    # ì¤‘ì•™ì— í°ìƒ‰ ì›ì„ ì¶”ê°€í•˜ì—¬ ë„ë„› ëª¨ì–‘ ë§Œë“¤ê¸°\n",
    "    centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "    \n",
    "    # ë¹„ìœ¨ í…ìŠ¤íŠ¸ ì„¤ì •\n",
    "    plt.setp(autotexts, size=10, weight=\"bold\", color=\"white\")\n",
    "    ax.set_title(\"Donut Chart Example\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "# ì„ í˜• ì°¨íŠ¸ ê·¸ë¦¬ê¸° í•¨ìˆ˜\n",
    "def draw_line_chart(x, y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y, marker='o')\n",
    "    ax.set_title(\"Line Chart Example\")\n",
    "    ax.set_xlabel(\"X-axis\")\n",
    "    ax.set_ylabel(\"Y-axis\")\n",
    "    ax.grid()\n",
    "    return fig\n",
    "\n",
    "def show():\n",
    "    st.title(\"ì°¨íŠ¸ ë° ì¸¡ì •ë‚´ìš©\")\n",
    "\n",
    "    # 3ê°œì˜ ì—´ ìƒì„±\n",
    "    col1, spacer1, col2, spacer2, col3 = st.columns([30, 5, 40, 5, 30])\n",
    "\n",
    "\n",
    "    # Column 1: ë„ë„› ì°¨íŠ¸\n",
    "    with col1:\n",
    "        st.header(\"Column 1: Donut Chart\")\n",
    "        st.write(\"This column is narrow.\")\n",
    "        # ë°ì´í„° ì¤€ë¹„\n",
    "        labels = ['Category A', 'Category B', 'Category C', 'Category D']\n",
    "        sizes = [15, 30, 45, 10]\n",
    "        colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
    "        \n",
    "        # ë„ë„› ì°¨íŠ¸ ê·¸ë¦¬ê¸°\n",
    "        donut_chart = draw_donut_chart(labels, sizes, colors)\n",
    "        st.pyplot(donut_chart)\n",
    "\n",
    "    # Column 2: ì„ í˜• ì°¨íŠ¸\n",
    "    with col2:\n",
    "        st.header(\"Column 2: Line Chart\")\n",
    "        st.write(\"This column is wider.\")\n",
    "        # ì„ì˜ì˜ ë°ì´í„° ìƒì„±\n",
    "        x = np.linspace(0, 10, 100)\n",
    "        y = np.sin(x)\n",
    "\n",
    "        # ì„ í˜• ì°¨íŠ¸ ê·¸ë¦¬ê¸°\n",
    "        line_chart = draw_line_chart(x, y)\n",
    "        st.pyplot(line_chart)\n",
    "\n",
    "    # Column 3: ë©”íŠ¸ë¦­\n",
    "    with col3:\n",
    "        st.header(\"Column 3: Metrics\")\n",
    "        st.write(\"This column is narrow.\")\n",
    "        st.metric(label=\"Total Sales\", value=\"$10,000\", delta=\"$1,000\")\n",
    "        st.metric(label=\"New Customers\", value=\"150\", delta=\"20\")\n",
    "        st.metric(label=\"Conversion Rate\", value=\"5%\", delta=\"-1%\")\n",
    "\n",
    "        with st.expander('About', expanded=True):\n",
    "             st.write('''\n",
    "            - Data: [U.S. Census Bureau](<https://www.census.gov/data/datasets/time-series/demo/popest/2010s-state-total.html>).\n",
    "            - :orange[**Gains/Losses**]: states with high inbound/ outbound migration for selected year\n",
    "            - :orange[**States Migration**]: percentage of states with annual inbound/ outbound migration > 50,000\n",
    "            ''')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show()\n",
    "\n",
    "# --- Content from /mnt/data/Home.py ---\n",
    "\n",
    "# í˜ì´ì§€ ì œëª© ì„¤ì •\n",
    "st.set_page_config(\n",
    "    page_title=\"MISA\",\n",
    "    page_icon=\"ğŸ©»\",\n",
    "    initial_sidebar_state=\"expanded\")\n",
    "\n",
    "\n",
    "\n",
    "# ì œëª©\n",
    "st.title(\"MIAS\")\n",
    "# ì†Œì œëª©\n",
    "st.subheader('ì•ˆë…•í•˜ì„¸ìš”. ì´ê±° ë§Œë“œëŠ”ë° ê²ë‚˜ í˜ë“¤ì—ˆì–´ìš”.. ì´ í™ˆì—” ')\n",
    "st.subheader('íŒ€ì› ì†Œê°œë¼ë˜ì§€ ê°„ë‹¨í•œ ë¬¸êµ¬ ë„£ìœ¼ë©´ ì–´ë–¨ê¹Œìš”??')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIAS",
   "language": "python",
   "name": "mias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
